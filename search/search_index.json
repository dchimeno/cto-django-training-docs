{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Abstract \u00b6 The Django course is a workshop to bring developers close to the Django philosophy, the way that it works and the common pitfalls every developer falls at least once by means of the creation of a project where people will be able to apply the different concepts addressed in the course. The only requirement is having a minimal knowledge of Python syntax. You will be able to learn how Django 2 works and how works its MVT based on Model, Views and Template. We will also put focus on the best-practices that we should follow in a Django project while creating a full project with some advanced techniques. We will create an API with Django and we will show how to create test for the entire application. Schedule: 10:00 \u2192 11:45 - Introduction and models. 12:00 \u2192 13:30 - Models. 13:30 \u2192 15:00 - Lunch 15:00 \u2192 16:15 - Views 16:30 \u2192 17:45 - Testing and Extra. Enjoy it!","title":"Abstract"},{"location":"#abstract","text":"The Django course is a workshop to bring developers close to the Django philosophy, the way that it works and the common pitfalls every developer falls at least once by means of the creation of a project where people will be able to apply the different concepts addressed in the course. The only requirement is having a minimal knowledge of Python syntax. You will be able to learn how Django 2 works and how works its MVT based on Model, Views and Template. We will also put focus on the best-practices that we should follow in a Django project while creating a full project with some advanced techniques. We will create an API with Django and we will show how to create test for the entire application. Schedule: 10:00 \u2192 11:45 - Introduction and models. 12:00 \u2192 13:30 - Models. 13:30 \u2192 15:00 - Lunch 15:00 \u2192 16:15 - Views 16:30 \u2192 17:45 - Testing and Extra. Enjoy it!","title":"Abstract"},{"location":"extra/","text":"Present and future of Django \u00b6 Django has evolved in a way not too much frameworks have done in the last 15 years. It has all the features it can have and is very mature and secure. But new challenges arise: Microservices More and more speed required Websockets New async frameworks in python Running python is slower New languages No only SQL FUTURE?: DJANGO ASYNC DEP: https://github.com/andrewgodwin/deps/blob/async/draft/0009-async.rst https://bit.ly/2EsoRrc","title":"5. Extra"},{"location":"extra/#present-and-future-of-django","text":"Django has evolved in a way not too much frameworks have done in the last 15 years. It has all the features it can have and is very mature and secure. But new challenges arise: Microservices More and more speed required Websockets New async frameworks in python Running python is slower New languages No only SQL FUTURE?: DJANGO ASYNC DEP: https://github.com/andrewgodwin/deps/blob/async/draft/0009-async.rst https://bit.ly/2EsoRrc","title":"Present and future of Django"},{"location":"introduction/","text":"Django is a Python-based web framework, which primary goal is to easy the creation of complex, relational database-driven websites. History \u00b6 Django was created in a newspaper in 2003 and released to the public in 2005. At that time, Internet (2.0) was full of PHP sites, SEO started to be a thing. So, Django is a framework with 15+ years of existence, that has evolved at the same time as the web. Main Releases: \u00b6 Version Year Major new features 0.90 2005 First release 1.0 2008 API Stability, admin 1.1 2009 Aggregates, transactions based tests 1.2 2010 Multiple DB connections, CSRF 1.3 2011 Class Based Views 1.4 LTS 2012 First release 1.5 2013 Python 3 Support. Configurable user model 1.6 2013 DB Transaction, Connection pooling 1.7 2014 Migrations in core 1.8 LTS 2015 Support for jinja template engine. contrib.postgres 1.9 2015 Password validation. New admin style. 1.10 2016 Full text search Postgres. New middleware. 1.11 LTS 2017 Latest to support python 2.7 (Abril 2020) 2.0 2017 Python3 only. Simpler URL router. Mobile admin 2.1 2018 CheckConstraint on models. More inspectdb and migrations options 2.2 LTS 2019 More Postgres Indexes Releases support \u00b6 Mainstream support is eight months per release. LTS are supported a total of three years since go public. Since 2.0, there is a change in version format. 2.0 - 8 months 2.1 - 8 months 2.2 LTS - 8 months + 28 months of extended support. 3.0 - 8 months 3.1 - 8 months 3.2 LTS - 8 months + 28 months of extended support. Extended support \u2192 Any security or loss data bug will be applied. Philosophy \u00b6 Loose coupling -> Various layers of the framework shouldn't know about each other. Models doesn't know about how data is displayed. Views doesn't care which template system is in use. Templates knows nothing about web requests. Quick development Django should allow for quick Web development and include everything needed for most web apps. Don\u2019t repeat yourself (DRY) Every distinct concept and/or piece of data should live in one, and only one, place. Redundancy is bad MTV vs MVC \u00b6 The pattern Model-Template-View used in Django is a bit different from traditional Model-View-Controller. In a typical MVC architecture: In Django MTV: So a correlation could be: Django MTV \u2192 MVC MODEL \u2192 MODEL TEMPLATE \u2192 VIEW Django it self \u2192 CONTROLLER View -> Request / Response. At the end of the day, of course, it comes down to getting stuff done. And, regardless of how things are named, Django gets stuff done in a way that\u2019s most logical to us. Apps \u00b6 It is important to understand that a Django application is just a set of code that interacts with various parts of the framework. There\u2019s no such thing as an Application object. However, there\u2019s a few places where Django needs to interact with installed applications, mainly for configuration and also for introspection. That\u2019s why the application registry maintains metadata in an AppConfig instance for each installed application. A Django app is a small library representing a discrete part of a larger project. For example, our blog web application might have an app for posts, one for static pages like an About page called pages, and another app called payments to charge logged-in subscribers. How to select a good app for our project \u00b6 Check the app is compatible with our Django version Check the app is compatible with our Python version Check app history (maturity, contributors, recent commit history...). Not give too much relevance to Check Django packages if is people using it. Prefer those apps that are maintained by an organization instead of a personal contributor. Example: Jazzband Components \u00b6 Django is sometimes called as a macro-framework, opposed as others like Flask, Bottle, web.py, etc. The idea behind Django is follow Python philosophy of batteries included, although all components are quite easy extended, modified or replaced. A brief list of built-in in a high level view components. Admin Forms Cache Templates Migrations StaticFiles Email Internationalization User Localization Permissions Testing ORM Signals Checks Setting up the project \u00b6 In order to follow the tutorial we'll need Docker and Docker-compose installed. 1 2 3 git clone git@github.com:Telefonica/cto-django-training-code.git cp .env.example .env docker-compose up After that you should see at http://localhost:8000 Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 . \u251c\u2500\u2500 accounts \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 migrations \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 admin.py \u2502 \u251c\u2500\u2500 apps.py \u2502 \u251c\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 tests.py \u2502 \u2514\u2500\u2500 views.py \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 settings \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 urls.py \u2502 \u2514\u2500\u2500 wsgi.py \u251c\u2500\u2500 nodes \u2502 \u251c\u2500\u2500 migrations \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 admin.py \u2502 \u251c\u2500\u2500 apps.py \u2502 \u251c\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 tests.py \u2502 \u2514\u2500\u2500 views.py \u251c\u2500\u2500 requirements \u2502 \u251c\u2500\u2500 base.txt \u2502 \u251c\u2500\u2500 dev.txt \u2502 \u2514\u2500\u2500 prod.txt \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 manage.py \u2514\u2500\u2500 wait-for-it.sh After this, create a new user in order to enter the admin: In another terminal in the same directory: 1 docker - compose exec web python manage . py createsuperuser Go to http://localhost:8000/config_admin/ and check you can login.","title":"1. Introduction"},{"location":"introduction/#history","text":"Django was created in a newspaper in 2003 and released to the public in 2005. At that time, Internet (2.0) was full of PHP sites, SEO started to be a thing. So, Django is a framework with 15+ years of existence, that has evolved at the same time as the web.","title":"History"},{"location":"introduction/#main-releases","text":"Version Year Major new features 0.90 2005 First release 1.0 2008 API Stability, admin 1.1 2009 Aggregates, transactions based tests 1.2 2010 Multiple DB connections, CSRF 1.3 2011 Class Based Views 1.4 LTS 2012 First release 1.5 2013 Python 3 Support. Configurable user model 1.6 2013 DB Transaction, Connection pooling 1.7 2014 Migrations in core 1.8 LTS 2015 Support for jinja template engine. contrib.postgres 1.9 2015 Password validation. New admin style. 1.10 2016 Full text search Postgres. New middleware. 1.11 LTS 2017 Latest to support python 2.7 (Abril 2020) 2.0 2017 Python3 only. Simpler URL router. Mobile admin 2.1 2018 CheckConstraint on models. More inspectdb and migrations options 2.2 LTS 2019 More Postgres Indexes","title":"Main Releases:"},{"location":"introduction/#releases-support","text":"Mainstream support is eight months per release. LTS are supported a total of three years since go public. Since 2.0, there is a change in version format. 2.0 - 8 months 2.1 - 8 months 2.2 LTS - 8 months + 28 months of extended support. 3.0 - 8 months 3.1 - 8 months 3.2 LTS - 8 months + 28 months of extended support. Extended support \u2192 Any security or loss data bug will be applied.","title":"Releases support"},{"location":"introduction/#philosophy","text":"Loose coupling -> Various layers of the framework shouldn't know about each other. Models doesn't know about how data is displayed. Views doesn't care which template system is in use. Templates knows nothing about web requests. Quick development Django should allow for quick Web development and include everything needed for most web apps. Don\u2019t repeat yourself (DRY) Every distinct concept and/or piece of data should live in one, and only one, place. Redundancy is bad","title":"Philosophy"},{"location":"introduction/#mtv-vs-mvc","text":"The pattern Model-Template-View used in Django is a bit different from traditional Model-View-Controller. In a typical MVC architecture: In Django MTV: So a correlation could be: Django MTV \u2192 MVC MODEL \u2192 MODEL TEMPLATE \u2192 VIEW Django it self \u2192 CONTROLLER View -> Request / Response. At the end of the day, of course, it comes down to getting stuff done. And, regardless of how things are named, Django gets stuff done in a way that\u2019s most logical to us.","title":"MTV vs MVC"},{"location":"introduction/#apps","text":"It is important to understand that a Django application is just a set of code that interacts with various parts of the framework. There\u2019s no such thing as an Application object. However, there\u2019s a few places where Django needs to interact with installed applications, mainly for configuration and also for introspection. That\u2019s why the application registry maintains metadata in an AppConfig instance for each installed application. A Django app is a small library representing a discrete part of a larger project. For example, our blog web application might have an app for posts, one for static pages like an About page called pages, and another app called payments to charge logged-in subscribers.","title":"Apps"},{"location":"introduction/#how-to-select-a-good-app-for-our-project","text":"Check the app is compatible with our Django version Check the app is compatible with our Python version Check app history (maturity, contributors, recent commit history...). Not give too much relevance to Check Django packages if is people using it. Prefer those apps that are maintained by an organization instead of a personal contributor. Example: Jazzband","title":"How to select a good app for our project"},{"location":"introduction/#components","text":"Django is sometimes called as a macro-framework, opposed as others like Flask, Bottle, web.py, etc. The idea behind Django is follow Python philosophy of batteries included, although all components are quite easy extended, modified or replaced. A brief list of built-in in a high level view components. Admin Forms Cache Templates Migrations StaticFiles Email Internationalization User Localization Permissions Testing ORM Signals Checks","title":"Components"},{"location":"introduction/#setting-up-the-project","text":"In order to follow the tutorial we'll need Docker and Docker-compose installed. 1 2 3 git clone git@github.com:Telefonica/cto-django-training-code.git cp .env.example .env docker-compose up After that you should see at http://localhost:8000","title":"Setting up the project"},{"location":"introduction/#structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 . \u251c\u2500\u2500 accounts \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 migrations \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 admin.py \u2502 \u251c\u2500\u2500 apps.py \u2502 \u251c\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 tests.py \u2502 \u2514\u2500\u2500 views.py \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 settings \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 urls.py \u2502 \u2514\u2500\u2500 wsgi.py \u251c\u2500\u2500 nodes \u2502 \u251c\u2500\u2500 migrations \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 admin.py \u2502 \u251c\u2500\u2500 apps.py \u2502 \u251c\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 tests.py \u2502 \u2514\u2500\u2500 views.py \u251c\u2500\u2500 requirements \u2502 \u251c\u2500\u2500 base.txt \u2502 \u251c\u2500\u2500 dev.txt \u2502 \u2514\u2500\u2500 prod.txt \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 manage.py \u2514\u2500\u2500 wait-for-it.sh After this, create a new user in order to enter the admin: In another terminal in the same directory: 1 docker - compose exec web python manage . py createsuperuser Go to http://localhost:8000/config_admin/ and check you can login.","title":"Structure"},{"location":"model/","text":"Django has a model centric approach and the underlying ORM is a heavy coupled part of the system. In this part you'll learn: How to define relational models. How to create and perform migrations How to add them to the admin. Shell to the rescue (ipython + django_extensions) How to auto document relational model. How to auto generate development data for them. How to avoid common N+1 problem. Some aggregated queries. It all start with a definition of a problem that we map to entities called models. A simple model definition could be: 1 2 3 4 5 6 7 8 9 from django.db import models class Article ( models . Model ): pub_date = models . DateField () headline = models . CharField ( max_length = 200 ) content = models . TextField () def __str__ ( self ): return f \"{self.headline} - {self.content}\" Field reference: https://docs.djangoproject.com/en/2.1/ref/models/fields/#field-types Relations \u00b6 There are three types of relations between entities: 1:1 \u2192 OneToOneField n:1 \u2192 ManyToOne n:m \u2192 ManyToMany Exercise: Given the references for fields and relations, create three models for Node , Stream and Data with the description: Node is like a IoT device that could has a unique name , has two node_type : white and black, could be enabled or not (default is enabled) and has 0 or more Stream Stream is the channel for we can retrieve different data in nodes, has name , enabled and a relation with Node. Data is where we we store data for each Stream and has timestamp with a default value to the current timestamp, a data field where we actually stores floats, and a relation with Stream After making the models, we should create and execute the migrations: 1 docker-compose exec web python manage.py makemigrations 1 docker-compose exec web python manage.py migrate Admin \u00b6 Now we want to display data in a way we can list, modify it and probably add some actions. The admin is intented for staff, superusers, managers, etc. but never end clients (customers) The admin is very extensible and customizable, it has a lot of magic, but it does the job 90% of the times saving hours of creating a custom backoffice. Exercise: Now that we have the models (tables) created in the database, we will add them to the admin. Following the below example, create the classes for 1 2 3 4 5 6 7 from django.contrib import admin from nodes.models import Node class NodeAdmin ( admin . ModelAdmin ): pass admin . site . register ( NodeAdmin , NodeAdmin ) Shell to the rescue \u00b6 We just notice we can create, modify, delete... entries from the admin panel, but we are developers, right? Thanks to ipython and django_extensions we'll have a productive shell to interact without code and data. 1 docker-compose exec web python manage.py shell_plus --ipython --print-sql Now we have a shell history (Cmd+R), auto loaded models and most used functions, and we can see sql directly in our shell. Let's try with some code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create a node alcala_node = Node . objects . create ( name = 'Alcal\u00e1' , enabled = False , node_type = 'basic' ) # See all nodes Node . objects . all () # Create a Stream attached to the previous node. riego_stream = Stream . objects . create ( name = 'Riego' , enabled = False , node = alcala_node ) # See all streams attached to node Stream . objects . filter ( node = alcala_node ) riego_data = Data . objects . create ( data = 2.3 , stream = riego_stream ) Auto generating ER model \u00b6 This tool is provided by django_extensions and needs some system dependencies. Its great when you are developing a project with a lot of relations to have a better understating of them. Reference: https://django-extensions.readthedocs.io/en/latest/graph_models.html In this example we use pydot because graphviz is more complex to install. 1 docker-compose exec web python manage.py graph_models -a -g -o docs/graph_models.png Django project with existing database \u00b6 Until now we have created the models given a problem/specification, but there are cases when the database is already created (and probably with data). In this case, Django cover us with inspectdb 1 docker-compose exec web python manage.py inspectdb Generate development data \u00b6 Given we are working on a database driven project, we need data in order to develop and test our code. A common and simple approach is copy production data and dump it in the DB, but that obviously comes with drawbacks: Could contain sensitive data Production systems move slowly than development, so there could be missing columns/tables. Another approach is the use of fixtures, Django support them but: They are static. In case of large tables, the size is too much to put inside the repository. If you use a small subset of data, you are probably missing some challenges (real use of indexes, N+1).. There is another option to create dynamically data based on our previously created models and some annotated data. We'll use the Factory Boy library Main benefit: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class FooTests ( unittest . TestCase ): def test_with_factory_boy ( self ): # We need a 200\u20ac, paid order, shipping to australia, for a VIP customer order = OrderFactory ( amount = 200 , status = 'PAID' , customer__is_vip = True , address__country = 'AU' , ) # Run the tests here def test_without_factory_boy ( self ): address = Address ( street = \"42 fubar street\" , zipcode = \"42Z42\" , city = \"Sydney\" , country = \"AU\" , ) customer = Customer ( first_name = \"John\" , last_name = \"Doe\" , phone = \"+1234\" , email = \"john.doe@example.org\" , active = True , is_vip = True , address = address , ) # etc. Main drawbacks: In some case we could end with duplicated code. Real example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import datetime import factory # noqa import factory.fuzzy import pytz from django.contrib.auth import get_user_model from nodes.models import Data , Node , Stream class UserFactory ( factory . django . DjangoModelFactory ): class Meta : model = User is_superuser = False is_staff = False username = factory . Faker ( 'user_name' ) first_name = factory . Faker ( 'name' ) @factory.lazy_attribute def email ( self ): return ' %s @example.com' % self . username Exercise : With the given example, create a factory for our models: Node, Stream and Data. More Reference: https://factoryboy.readthedocs.io/en/latest/examples.html How to avoid common problems with relations \u00b6 Django querysets are lazy, that means that query against the database is not executed until the last possible moment. That means that we could easily trap into the N+1 problem. 1 2 3 4 5 # This block is 1 query for data # and 20 queries for each stream that is lazy-loaded data = Data . objects . all ()[ 0 : 19 ] for d in data : print ( d . data , d . stream . name ) Fix: 1 2 3 4 # only 1 query data = Data . objects . select_related ( 'stream' ) . all () for d in data : print ( d . data , d . stream . name ) Would result in 1 2 3 4 5 6 7 8 9 10 11 SELECT ` nodes_data ` . ` id ` , ` nodes_data ` . ` timestamp ` , ` nodes_data ` . ` data ` , ` nodes_data ` . ` stream_id ` , ` nodes_stream ` . ` id ` , ` nodes_stream ` . ` name ` , ` nodes_stream ` . ` enabled ` , ` nodes_stream ` . ` node_id ` FROM ` nodes_data ` INNER JOIN ` nodes_stream ` ON ( ` nodes_data ` . ` stream_id ` = ` nodes_stream ` . ` id ` ) select_related is used for ForeignKey relations, for ManyToMany relations we should use prefetch_related Aggregated queries. \u00b6 Aggregate calculates values for the entire queryset. 1 2 Book . objects . aggregate ( average_price = Avg ( 'price' )) # {'average_price': 34.35} Annotate calculates summary values for each item in the queryset. 1 2 3 q = Book . objects . annotate ( num_authors = Count ( 'authors' )) q [ 0 ] . num_authors # 2 Exercise. How many Streams are with the name Riego ? How many water has been registered for those streams? Which is the node who has registered more water?","title":"2. Model"},{"location":"model/#relations","text":"There are three types of relations between entities: 1:1 \u2192 OneToOneField n:1 \u2192 ManyToOne n:m \u2192 ManyToMany Exercise: Given the references for fields and relations, create three models for Node , Stream and Data with the description: Node is like a IoT device that could has a unique name , has two node_type : white and black, could be enabled or not (default is enabled) and has 0 or more Stream Stream is the channel for we can retrieve different data in nodes, has name , enabled and a relation with Node. Data is where we we store data for each Stream and has timestamp with a default value to the current timestamp, a data field where we actually stores floats, and a relation with Stream After making the models, we should create and execute the migrations: 1 docker-compose exec web python manage.py makemigrations 1 docker-compose exec web python manage.py migrate","title":"Relations"},{"location":"model/#admin","text":"Now we want to display data in a way we can list, modify it and probably add some actions. The admin is intented for staff, superusers, managers, etc. but never end clients (customers) The admin is very extensible and customizable, it has a lot of magic, but it does the job 90% of the times saving hours of creating a custom backoffice. Exercise: Now that we have the models (tables) created in the database, we will add them to the admin. Following the below example, create the classes for 1 2 3 4 5 6 7 from django.contrib import admin from nodes.models import Node class NodeAdmin ( admin . ModelAdmin ): pass admin . site . register ( NodeAdmin , NodeAdmin )","title":"Admin"},{"location":"model/#shell-to-the-rescue","text":"We just notice we can create, modify, delete... entries from the admin panel, but we are developers, right? Thanks to ipython and django_extensions we'll have a productive shell to interact without code and data. 1 docker-compose exec web python manage.py shell_plus --ipython --print-sql Now we have a shell history (Cmd+R), auto loaded models and most used functions, and we can see sql directly in our shell. Let's try with some code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create a node alcala_node = Node . objects . create ( name = 'Alcal\u00e1' , enabled = False , node_type = 'basic' ) # See all nodes Node . objects . all () # Create a Stream attached to the previous node. riego_stream = Stream . objects . create ( name = 'Riego' , enabled = False , node = alcala_node ) # See all streams attached to node Stream . objects . filter ( node = alcala_node ) riego_data = Data . objects . create ( data = 2.3 , stream = riego_stream )","title":"Shell to the rescue"},{"location":"model/#auto-generating-er-model","text":"This tool is provided by django_extensions and needs some system dependencies. Its great when you are developing a project with a lot of relations to have a better understating of them. Reference: https://django-extensions.readthedocs.io/en/latest/graph_models.html In this example we use pydot because graphviz is more complex to install. 1 docker-compose exec web python manage.py graph_models -a -g -o docs/graph_models.png","title":"Auto generating ER model"},{"location":"model/#django-project-with-existing-database","text":"Until now we have created the models given a problem/specification, but there are cases when the database is already created (and probably with data). In this case, Django cover us with inspectdb 1 docker-compose exec web python manage.py inspectdb","title":"Django project with existing database"},{"location":"model/#generate-development-data","text":"Given we are working on a database driven project, we need data in order to develop and test our code. A common and simple approach is copy production data and dump it in the DB, but that obviously comes with drawbacks: Could contain sensitive data Production systems move slowly than development, so there could be missing columns/tables. Another approach is the use of fixtures, Django support them but: They are static. In case of large tables, the size is too much to put inside the repository. If you use a small subset of data, you are probably missing some challenges (real use of indexes, N+1).. There is another option to create dynamically data based on our previously created models and some annotated data. We'll use the Factory Boy library Main benefit: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class FooTests ( unittest . TestCase ): def test_with_factory_boy ( self ): # We need a 200\u20ac, paid order, shipping to australia, for a VIP customer order = OrderFactory ( amount = 200 , status = 'PAID' , customer__is_vip = True , address__country = 'AU' , ) # Run the tests here def test_without_factory_boy ( self ): address = Address ( street = \"42 fubar street\" , zipcode = \"42Z42\" , city = \"Sydney\" , country = \"AU\" , ) customer = Customer ( first_name = \"John\" , last_name = \"Doe\" , phone = \"+1234\" , email = \"john.doe@example.org\" , active = True , is_vip = True , address = address , ) # etc. Main drawbacks: In some case we could end with duplicated code. Real example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import datetime import factory # noqa import factory.fuzzy import pytz from django.contrib.auth import get_user_model from nodes.models import Data , Node , Stream class UserFactory ( factory . django . DjangoModelFactory ): class Meta : model = User is_superuser = False is_staff = False username = factory . Faker ( 'user_name' ) first_name = factory . Faker ( 'name' ) @factory.lazy_attribute def email ( self ): return ' %s @example.com' % self . username Exercise : With the given example, create a factory for our models: Node, Stream and Data. More Reference: https://factoryboy.readthedocs.io/en/latest/examples.html","title":"Generate development data"},{"location":"model/#how-to-avoid-common-problems-with-relations","text":"Django querysets are lazy, that means that query against the database is not executed until the last possible moment. That means that we could easily trap into the N+1 problem. 1 2 3 4 5 # This block is 1 query for data # and 20 queries for each stream that is lazy-loaded data = Data . objects . all ()[ 0 : 19 ] for d in data : print ( d . data , d . stream . name ) Fix: 1 2 3 4 # only 1 query data = Data . objects . select_related ( 'stream' ) . all () for d in data : print ( d . data , d . stream . name ) Would result in 1 2 3 4 5 6 7 8 9 10 11 SELECT ` nodes_data ` . ` id ` , ` nodes_data ` . ` timestamp ` , ` nodes_data ` . ` data ` , ` nodes_data ` . ` stream_id ` , ` nodes_stream ` . ` id ` , ` nodes_stream ` . ` name ` , ` nodes_stream ` . ` enabled ` , ` nodes_stream ` . ` node_id ` FROM ` nodes_data ` INNER JOIN ` nodes_stream ` ON ( ` nodes_data ` . ` stream_id ` = ` nodes_stream ` . ` id ` ) select_related is used for ForeignKey relations, for ManyToMany relations we should use prefetch_related","title":"How to avoid common problems with relations"},{"location":"model/#aggregated-queries","text":"Aggregate calculates values for the entire queryset. 1 2 Book . objects . aggregate ( average_price = Avg ( 'price' )) # {'average_price': 34.35} Annotate calculates summary values for each item in the queryset. 1 2 3 q = Book . objects . annotate ( num_authors = Count ( 'authors' )) q [ 0 ] . num_authors # 2 Exercise. How many Streams are with the name Riego ? How many water has been registered for those streams? Which is the node who has registered more water?","title":"Aggregated queries."},{"location":"testing/","text":"Automated testing is an extremely useful bug-killing tool for the modern Web developer. For models and business logic \u00b6 Unit Testing for models and business logic. Example test case: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.test import TestCase from nodes.factories import NodeFactory from nodes import models class NodeTestCase ( TestCase ): def setUp ( self ): NodeFactory . create_batch ( 10 ) def test_node_has_a_name ( self ): for node in models . Node . objects . all (): self . assertIsNotNone ( node . name ) Exercise Write some tests for Data and Stream models. Useful tests \u00b6 When making a test for a specific view or function, it's important to query how many queries have been done in order to avoid possible performance regressions in the future. 1 2 3 4 5 6 7 8 class NodeTestCase ( TestCase ): def setUp ( self ): NodeFactory . create_batch ( 10 ) def test_node_only_one_query ( self ): with self . assertNumQueries ( 1 ): for node in models . Node . objects . all (): self . assertIsNotNone ( node . name ) Exercise : Create a test for the queries made in section project license Other tests \u00b6 It's also possible to integrate libraries to create selenium tests from Django but it's not covered here. Main reference: https://www.obeythetestinggoat.com/","title":"4. Testing"},{"location":"testing/#for-models-and-business-logic","text":"Unit Testing for models and business logic. Example test case: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.test import TestCase from nodes.factories import NodeFactory from nodes import models class NodeTestCase ( TestCase ): def setUp ( self ): NodeFactory . create_batch ( 10 ) def test_node_has_a_name ( self ): for node in models . Node . objects . all (): self . assertIsNotNone ( node . name ) Exercise Write some tests for Data and Stream models.","title":"For models and business logic"},{"location":"testing/#useful-tests","text":"When making a test for a specific view or function, it's important to query how many queries have been done in order to avoid possible performance regressions in the future. 1 2 3 4 5 6 7 8 class NodeTestCase ( TestCase ): def setUp ( self ): NodeFactory . create_batch ( 10 ) def test_node_only_one_query ( self ): with self . assertNumQueries ( 1 ): for node in models . Node . objects . all (): self . assertIsNotNone ( node . name ) Exercise : Create a test for the queries made in section project license","title":"Useful tests"},{"location":"testing/#other-tests","text":"It's also possible to integrate libraries to create selenium tests from Django but it's not covered here. Main reference: https://www.obeythetestinggoat.com/","title":"Other tests"},{"location":"views/","text":"Request-Response Cycle \u00b6 The request-response cycle is probably the most important part needed to understand in a Django project. WSGI : Python Web Server Gateway Interface https://www.python.org/dev/peps/pep-0333/ Middleware Order \u00b6 Middleware is a framework of hooks into Django\u2019s request/response processing. It\u2019s a light, low-level \u201cplugin\u201d system for globally altering Django\u2019s input or output. https://docs.djangoproject.com/en/2.1/topics/http/middleware/ Exercise: Create a middleware that logs/prints all requests durations. Reference: https://docs.djangoproject.com/en/2.1/topics/http/middleware/ Create a basic view \u00b6 Given one of the previous query we saw in on the other chapter. Create a function based view that returns a json of that queryset. Reference: https://docs.djangoproject.com/en/2.2/ref/request-response/#jsonresponse-objects 1 2 def riego_streams ( request ): pass Creating a basic API \u00b6 We'll create some endpoints to expose data with It's not mandatory to use DRF, we could use it plain old Django. DRF, with a cost of abstractions, some verbosity (and some performance) gives us: Concern separation, more plugable than function based views (Validation, Pagination, Renderers, Parsers, Permissions, Rate-Limit, Auth plugins..) Main concepts: Serializers: \u00b6 1 2 3 4 5 6 7 8 9 # serializers.py from rest_framework.serializers import ModelSerializer from nodes import models class NodeSerializer ( ModelSerializer ): class Meta : model = models . Node fields = '__all__' Viewsets \u00b6 Quite abstract class to handle various actions (list, retrieve, update, delete..) 1 2 3 4 5 6 7 8 # views.py from rest_framework import viewsets from nodes import models class NodeView ( viewsets . ModelViewSet ): queryset = models . Node . objects . all () serializer_class = NodeSerializer 1 2 3 4 5 6 7 8 9 10 11 12 # urls.py from rest_framework import routers router = routers . SimpleRouter () router . register ( r 'data' , views . NodeView ) urlpatterns = [ # Not default admin because of possible attacks to known urls # The admin can be removed if it's not gonna be used path ( 'config_admin/' , admin . site . urls ), ] + router . urls Exercise: Given the above examples, create endpoints for stream and data. No need for nested them \u2192 Flat is better than nested Django and OpenAPI \u00b6 Swagger 2.0 OpenAPI 3.0 When working with code and a API spec there are three options. 1. Create an API spec and Code it separately Pros: - Simpler, there is no directly relation between API spec and code. - Easier to integrate in current projects, as it doesnt make any assumption about how is coded. Cons: - It's easier to make mistakes by the developer due to not having fully syncronized Spec and Code. 2. API First way This is probably the most elegant solution, and other tools in the python ecosystem use this like Connexion . In this way we would write first the 4 th platform spec, and we would have the incoming request validated thought that spec. Unfortunately, I haven't found a way to integrate something like the above tool in a Django project. The bravado-core library seems promising, but I haven't tested deeply. 3. Code first way In this way, we code the API, for example with DRF and its serializers and the tooling will create and OpenAPI spec for us based on the code. This is the approach we have used in SS-API and we are quite happy with it, but note there is no 4 th integration there, so there is not any custom values as scope in the spec. We serve a /schema.json file in our service in order to integrate it with luca apidocs DRF-YASG \u00b6 drf-yasg Automatic generation of Swagger 2.0 spec based on DRF serializers and views (introspection) and some annotations. Business Logic on Django \u00b6 Never make business logic in VIEWS. Views are for validating input and returning responses. (Difficult with DRF) Django advice for FAT models \u2192 It's ok on little to medium projects. Prefer using managers and querysets to chain filters, models for simple properties Create another layer called Service to reuse business logic. References: https://www.youtube.com/watch?v=Fqhpr_SXqzs https://www.youtube.com/watch?v=yG3ZdxBb1oo","title":"3. Views"},{"location":"views/#request-response-cycle","text":"The request-response cycle is probably the most important part needed to understand in a Django project. WSGI : Python Web Server Gateway Interface https://www.python.org/dev/peps/pep-0333/","title":"Request-Response Cycle"},{"location":"views/#middleware-order","text":"Middleware is a framework of hooks into Django\u2019s request/response processing. It\u2019s a light, low-level \u201cplugin\u201d system for globally altering Django\u2019s input or output. https://docs.djangoproject.com/en/2.1/topics/http/middleware/ Exercise: Create a middleware that logs/prints all requests durations. Reference: https://docs.djangoproject.com/en/2.1/topics/http/middleware/","title":"Middleware Order"},{"location":"views/#create-a-basic-view","text":"Given one of the previous query we saw in on the other chapter. Create a function based view that returns a json of that queryset. Reference: https://docs.djangoproject.com/en/2.2/ref/request-response/#jsonresponse-objects 1 2 def riego_streams ( request ): pass","title":"Create a basic view"},{"location":"views/#creating-a-basic-api","text":"We'll create some endpoints to expose data with It's not mandatory to use DRF, we could use it plain old Django. DRF, with a cost of abstractions, some verbosity (and some performance) gives us: Concern separation, more plugable than function based views (Validation, Pagination, Renderers, Parsers, Permissions, Rate-Limit, Auth plugins..) Main concepts:","title":"Creating a basic API"},{"location":"views/#serializers","text":"1 2 3 4 5 6 7 8 9 # serializers.py from rest_framework.serializers import ModelSerializer from nodes import models class NodeSerializer ( ModelSerializer ): class Meta : model = models . Node fields = '__all__'","title":"Serializers:"},{"location":"views/#viewsets","text":"Quite abstract class to handle various actions (list, retrieve, update, delete..) 1 2 3 4 5 6 7 8 # views.py from rest_framework import viewsets from nodes import models class NodeView ( viewsets . ModelViewSet ): queryset = models . Node . objects . all () serializer_class = NodeSerializer 1 2 3 4 5 6 7 8 9 10 11 12 # urls.py from rest_framework import routers router = routers . SimpleRouter () router . register ( r 'data' , views . NodeView ) urlpatterns = [ # Not default admin because of possible attacks to known urls # The admin can be removed if it's not gonna be used path ( 'config_admin/' , admin . site . urls ), ] + router . urls Exercise: Given the above examples, create endpoints for stream and data. No need for nested them \u2192 Flat is better than nested","title":"Viewsets"},{"location":"views/#django-and-openapi","text":"Swagger 2.0 OpenAPI 3.0 When working with code and a API spec there are three options. 1. Create an API spec and Code it separately Pros: - Simpler, there is no directly relation between API spec and code. - Easier to integrate in current projects, as it doesnt make any assumption about how is coded. Cons: - It's easier to make mistakes by the developer due to not having fully syncronized Spec and Code. 2. API First way This is probably the most elegant solution, and other tools in the python ecosystem use this like Connexion . In this way we would write first the 4 th platform spec, and we would have the incoming request validated thought that spec. Unfortunately, I haven't found a way to integrate something like the above tool in a Django project. The bravado-core library seems promising, but I haven't tested deeply. 3. Code first way In this way, we code the API, for example with DRF and its serializers and the tooling will create and OpenAPI spec for us based on the code. This is the approach we have used in SS-API and we are quite happy with it, but note there is no 4 th integration there, so there is not any custom values as scope in the spec. We serve a /schema.json file in our service in order to integrate it with luca apidocs","title":"Django and OpenAPI"},{"location":"views/#drf-yasg","text":"drf-yasg Automatic generation of Swagger 2.0 spec based on DRF serializers and views (introspection) and some annotations.","title":"DRF-YASG"},{"location":"views/#business-logic-on-django","text":"Never make business logic in VIEWS. Views are for validating input and returning responses. (Difficult with DRF) Django advice for FAT models \u2192 It's ok on little to medium projects. Prefer using managers and querysets to chain filters, models for simple properties Create another layer called Service to reuse business logic. References: https://www.youtube.com/watch?v=Fqhpr_SXqzs https://www.youtube.com/watch?v=yG3ZdxBb1oo","title":"Business Logic on Django"}]}